import numpy as np
import pandas as pd
import torch
from typing import Dict, List, Tuple, Optional
import re
from pathlib import Path

class SPE9ProfessionalParser:
    """Professional parser for real SPE9 data"""
    
    def __init__(self, config: SPE9GridConfig):
        self.config = config
        self.grid_data = None
        self.well_data = None
        self.production_data = None
        
    def parse_complete_spe9_system(self, data_directory: str) -> Dict[str, torch.Tensor]:
        """Parse complete SPE9 system and generate training tensors"""
        print("ðŸŽ¯ Parsing Complete SPE9 Reservoir System...")
        
        # 1. Parse main file
        main_data = self._parse_spe9_data_file(data_directory)
        
        # 2. Parse real permeability data
        perm_data = self._parse_real_permeability_data(data_directory)
        
        # 3. Create grid data
        grid_tensors = self._create_grid_tensors(main_data, perm_data)
        
        # 4. Generate realistic production data
        production_tensors = self._generate_realistic_production_data()
        
        # 5. Combine data
        complete_data = {
            **grid_tensors,
            **production_tensors,
            'static_features': self._create_static_features(grid_tensors),
            'dynamic_features': self._create_dynamic_features(production_tensors)
        }
        
        print("âœ… Complete SPE9 system parsed successfully!")
        return complete_data
    
    def _parse_real_permeability_data(self, data_directory: str) -> Dict[str, np.ndarray]:
        """Parse real permeability data from PERMVALUES.DATA"""
        perm_file = Path(data_directory) / "PERMVALUES.DATA"
        
        if not perm_file.exists():
            raise FileNotFoundError(f"PERMVALUES.DATA not found in {data_directory}")
        
        with open(perm_file, 'r') as f:
            content = f.read()
        
        # Parse layered structure
        permx_data = self._parse_layered_permeability(content, 'PERMX')
        
        return {
            'PERMX': permx_data,
            'PERMY': permx_data,  # Assume isotropic in x-y
            'PERMZ': permx_data * 0.1  # Typical vertical anisotropy
        }
    
    def _parse_layered_permeability(self, content: str, keyword: str) -> np.ndarray:
        """Parse layered permeability data"""
        print(f"ðŸ” Parsing {keyword} data...")
        
        # Extract data for each layer
        layer_pattern = r'-- LAYER\s+(\d+)(.*?)(?=-- LAYER|\Z)'
        layers_data = []
        
        for layer_match in re.finditer(layer_pattern, content, re.DOTALL):
            layer_num = int(layer_match.group(1))
            layer_content = layer_match.group(2)
            
            # Parse rows for each layer
            row_data = self._parse_layer_rows(layer_content)
            layers_data.append(row_data)
        
        # Convert to 3D array
        perm_array = np.stack(layers_data, axis=0)  # Shape: (nz, ny, nx)
        return perm_array
    
    def _parse_layer_rows(self, layer_content: str) -> np.ndarray:
        """Parse rows for each layer"""
        row_pattern = r'-- ROW\s+(\d+)(.*?)(?=-- ROW|\Z)'
        rows_data = []
        
        for row_match in re.finditer(row_pattern, layer_content, re.DOTALL):
            row_num = int(row_match.group(1))
            row_content = row_match.group(2)
            
            # Extract numerical values
            numbers = re.findall(r'[\d.]+(?:e-?\d+)?', row_content)
            row_values = [float(x) for x in numbers]
            rows_data.append(row_values)
        
        return np.array(rows_data)
    
    def _create_grid_tensors(self, main_data: Dict, perm_data: Dict) -> Dict[str, torch.Tensor]:
        """Create grid tensors for training"""
        # Create 3D grid
        nx, ny, nz = self.config.nx, self.config.ny, self.config.nz
        
        # Static tensors
        static_tensors = {
            'permeability_x': torch.tensor(perm_data['PERMX'], dtype=torch.float32),
            'permeability_z': torch.tensor(perm_data['PERMZ'], dtype=torch.float32),
            'porosity': self._create_porosity_tensor(),
            'depth': self._create_depth_tensor(),
            'region': self._create_region_tensor()
        }
        
        return static_tensors
    
    def _create_porosity_tensor(self) -> torch.Tensor:
        """Create porosity tensor based on layers"""
        porosity_tensor = torch.zeros(self.config.nz, self.config.ny, self.config.nx)
        
        for k in range(self.config.nz):
            porosity_tensor[k] = self.config.porosity_layers[k]
            
        return porosity_tensor
    
    def _generate_realistic_production_data(self) -> Dict[str, torch.Tensor]:
        """Generate realistic production data based on SPE9"""
        time_steps = 900  # 900 days simulation
        
        # Field-level production data
        field_data = {
            'FOPR': self._generate_field_oil_production(time_steps),  # Field Oil Production Rate
            'FGPR': self._generate_field_gas_production(time_steps),  # Field Gas Production Rate  
            'FWPR': self._generate_field_water_production(time_steps), # Field Water Production Rate
            'FGOR': self._generate_field_gor(time_steps),  # Field Gas-Oil Ratio
        }
        
        # Well data
        well_data = self._generate_well_production_data(time_steps)
        
        return {**field_data, **well_data}
    
    def _generate_field_oil_production(self, time_steps: int) -> torch.Tensor:
        """Generate field oil production data"""
        # Based on SPE9 specs: 25 producers with 1500 STB/D + injector
        base_production = torch.ones(time_steps) * 25 * 1500  # STB/D
        
        # Add realistic behavior
        time = torch.arange(time_steps).float()
        
        # Production decline over time
        decline = torch.exp(-time / 2000)  # Exponential decline
        
        # Random fluctuations
        noise = torch.normal(0, 500, (time_steps,))
        
        production = base_production * decline + noise
        return production
    
    def _generate_field_gas_production(self, time_steps: int) -> torch.Tensor:
        """Generate field gas production data"""
        # Gas production follows oil production with increasing GOR
        time = torch.arange(time_steps).float()
        base_gas = torch.ones(time_steps) * 50000  # MCF/D
        
        # Increasing GOR trend
        gor_increase = 1.0 + (time / time_steps) * 0.5
        
        production = base_gas * gor_increase
        return production
    
    def _generate_field_water_production(self, time_steps: int) -> torch.Tensor:
        """Generate field water production data"""
        time = torch.arange(time_steps).float()
        
        # Water breakthrough and increasing water cut
        water_cut = torch.sigmoid((time - 300) / 100) * 0.8
        
        base_water = torch.ones(time_steps) * 1000  # STB/D
        production = base_water * water_cut
        
        return production
    
    def _generate_field_gor(self, time_steps: int) -> torch.Tensor:
        """Generate field gas-oil ratio data"""
        time = torch.arange(time_steps).float()
        
        # Increasing GOR due to reservoir depletion
        base_gor = 1000  # SCF/STB
        gor_increase = 1.0 + (time / time_steps) * 1.0
        
        gor = torch.ones(time_steps) * base_gor * gor_increase
        return gor
    
    def _generate_well_production_data(self, time_steps: int) -> Dict[str, torch.Tensor]:
        """Generate individual well production data"""
        n_wells = 26  # 25 producers + 1 injector
        
        well_data = {}
        for i in range(n_wells):
            well_name = f'WELL_{i+1:02d}'
            
            if i == 0:  # Injector
                well_data[f'{well_name}_WIR'] = torch.ones(time_steps) * 5000  # Water injection
                well_data[f'{well_name}_BHP'] = torch.ones(time_steps) * 3500  # Bottom hole pressure
            else:  # Producers
                well_data[f'{well_name}_WOPR'] = torch.ones(time_steps) * 1500  # Oil production
                well_data[f'{well_name}_WGPR'] = torch.ones(time_steps) * 2000  # Gas production
                well_data[f'{well_name}_WWPR'] = torch.ones(time_steps) * 500   # Water production
                well_data[f'{well_name}_BHP'] = torch.ones(time_steps) * 1500   # Bottom hole pressure
        
        return well_data
    
    def _create_depth_tensor(self) -> torch.Tensor:
        """Create depth tensor"""
        nx, ny, nz = self.config.nx, self.config.ny, self.config.nz
        depth_tensor = torch.zeros(nz, ny, nx)
        
        # Create depth structure - increasing with layer
        for k in range(nz):
            layer_depth = 2000 + sum(self.config.dz[:k])  # Base depth + cumulative thickness
            depth_tensor[k] = layer_depth
            
        return depth_tensor
    
    def _create_region_tensor(self) -> torch.Tensor:
        """Create region tensor for geological zones"""
        nx, ny, nz = self.config.nx, self.config.ny, self.config.nz
        region_tensor = torch.zeros(nz, ny, nx)
        
        # Simple region assignment based on position
        for k in range(nz):
            if k < 5:
                region_tensor[k] = 1  # Upper zone
            elif k < 10:
                region_tensor[k] = 2  # Middle zone
            else:
                region_tensor[k] = 3  # Lower zone
                
        return region_tensor
    
    def _create_static_features(self, grid_tensors: Dict) -> torch.Tensor:
        """Create combined static features tensor"""
        features_list = [
            grid_tensors['permeability_x'].flatten(),
            grid_tensors['porosity'].flatten(),
            grid_tensors['depth'].flatten(),
            grid_tensors['region'].flatten()
        ]
        
        static_features = torch.stack(features_list, dim=1)
        return static_features
    
    def _create_dynamic_features(self, production_tensors: Dict) -> torch.Tensor:
        """Create combined dynamic features tensor"""
        # Use field-level production data as dynamic features
        dynamic_features_list = [
            production_tensors['FOPR'],
            production_tensors['FGPR'],
            production_tensors['FWPR'],
            production_tensors['FGOR']
        ]
        
        dynamic_features = torch.stack(dynamic_features_list, dim=1)
        return dynamic_features
    
    def _parse_spe9_data_file(self, data_directory: str) -> Dict:
        """Parse main SPE9 data file (placeholder implementation)"""
        # This would parse the main SPE9.DATA file
        # For now, return basic structure
        return {
            'title': 'SPE9 Comparative Solution Project',
            'grid_dimensions': (self.config.nx, self.config.ny, self.config.nz),
            'phases': ['OIL', 'WATER', 'GAS']
        }
